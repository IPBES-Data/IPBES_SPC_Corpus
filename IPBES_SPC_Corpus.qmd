---
title: 'Spatial Planning and Connectivity Corpus - Technical Background Report'
subtitle: 'IPBES Spatial Planning and Connectivity Assessment'
author:
  - name: 
        family: Krug
        given: Rainer M.    
    id: rmk
    orcid: 0000-0002-7490-0066
    email: Rainer.Krug@ssib.swiss, Rainer@Krugs.de
    roles: [author, editor] 
  - name: 
        family: Bishop
        given: Gabriella    
    id: gb
    orcid: ?????
    roles: [author] 
  - name: 
        family: Villasante
        given: Sebastian    
    id: sv
    orcid: 0000-0001-6296-4479
    roles: [author] 


abstract: > 
 To Be added

license: "CC BY"

doi: &doi 10.5281/zenodo.XXXXX

citation: 
  type: report
  container-title: 'IPBES Spatial Planning and Connectivity Assessment'
  doi: *doi
version: 0.0.1 

format:
    html:
        toc: true
        toc-depth: 5
        toc_expand: true
        embed-resources: true
        code-fold: true
        code-summary: 'Show the code'
        grid:
            sidebar-width: 0px
            body-width: 4000px
            margin-width: 200px
            gutter-width: 1.5rem      
        df-print: paged
        mermaid:
          theme: default
          themeVariables:
            clusterBkg: transparent
            clusterBorder: transparent
execute:
  message: NA
params:

    search_terms: !expr >-
      list(
        spc_corpus =  yaml::read_yaml(file.path("input", "search_terms", "spc_corpus.yaml")),
        chapter_1 = yaml::read_yaml(file.path("input", "search_terms", "chapter_1.yaml")),
        chapter_2 = yaml::read_yaml(file.path("input", "search_terms", "chapter_2.yaml")),
        chapter_3 = yaml::read_yaml(file.path("input", "search_terms", "chapter_3.yaml")),
        chapter_4 = yaml::read_yaml(file.path("input", "search_terms", "chapter_4.yaml")),
        chapter_5 = yaml::read_yaml(file.path("input", "search_terms", "chapter_5.yaml")),
        chapter_6 = yaml::read_yaml(file.path("input", "search_terms", "chapter_6.yaml"))
      )

    publication_date: !expr >-
      list(
        from = '1992-01-01',
        to = '2025-12-31'
      )


    types: !expr read.csv(file.path("input", "openalex_types.csv"))
    types_filter: !expr read.csv(file.path("input", "openalex_types.csv")) |> dplyr::filter(Included) |> dplyr::pull(Type)

    key_papers: !expr >-
      list(
        connectivity = read.csv(file.path("input", "keypaper", "ecological_connectivity.csv")),
        planning     = read.csv(file.path("input", "keypaper", "spatial_planning.csv")),
        goldstandard = read.csv(file.path("input", "keypaper", "GoldStandardPapers.csv"), sep = ",")
      )

    output_dir: !expr file.path(".", "spc_corpus", "output")

    keyworks: !expr file.path(".", "spc_corpus", "output", "key_works")
    corpus: !expr file.path(".", "spc_corpus", "output", "corpus")
    chapter_1: !expr file.path(".", "spc_corpus", "output", "chapter_1")
    chapter_2: !expr file.path(".", "spc_corpus", "output", "chapter_2")
    chapter_3: !expr file.path(".", "spc_corpus", "output", "chapter_3")
    chapter_4: !expr file.path(".", "spc_corpus", "output", "chapter_4")
    chapter_5: !expr file.path(".", "spc_corpus", "output", "chapter_5")
    chapter_6: !expr file.path(".", "spc_corpus", "output", "chapter_6")

    # pages_dir: !expr file.path(".", "spc_corpus", "output", "pages")

    # corpus_dir: !expr file.path(".", "spc_corpus", "data", "corpus")

    sample_size: 10000
    mc.cores: 8
---

```{r}
#| label: setup
#| include: false

# paste(
#     "(", paste0(readLines(file.path("tca_corpus", "input", "search terms", "nature.txt")), collapse = "\n"), ") \nAND \n(", paste0(readLines(file.path("tca_corpus", "input", "search terms", "tfc.txt")), collapse = "\n"), ")"
# )

knitr::opts_chunk$set(message = NA)

build <- as.integer(readLines(file.path(".", "buildNo")))
build <- build + 1
writeLines(as.character(build), file.path(".", "buildNo"))

if (!exists("params")) {
  params <- rmarkdown::yaml_front_matter("./IPBES_SPC_Corpus.qmd")$params
}

knitr::opts_chunk$set(message = NA)

library(openalexR)
library(openalexPro)
library(arrow)

library(dplyr)
library(tibble)

# library(ggplot2)
# library(patchwork)
# library(igraph)
# library(ggraph)
# library(visNetwork)
# library(DT)

# library(tictoc)

# library(knitr)

# library(parquetize)
# library(purrr)
# library(base64enc)

# library(diffviewer)

# library(collapsibleTree)

# library(htmlwidgets)

# if (!require("IPBES.R")) {
#     install.packages("IPBES.R", repos = c("https://ipbes-data.r-universe.dev", "https://cloud.r-project.org"))
#     if (!require("IPBES.R")) {
#         stop("Package `IPBES.R` is not available and could not be installed!")
#     }
# }

lapply(
  list.files(
    file.path(".", "R"),
    full.names = TRUE
  ),
  source
)

dir.create(params$output_dir, recursive = TRUE, showWarnings = FALSE)
dir.create(params$keyworks, recursive = TRUE, showWarnings = FALSE)
dir.create(params$corpus, recursive = TRUE, showWarnings = FALSE)
dir.create(params$chapter_1, recursive = TRUE, showWarnings = FALSE)
dir.create(params$chapter_2, recursive = TRUE, showWarnings = FALSE)
dir.create(params$chapter_3, recursive = TRUE, showWarnings = FALSE)
dir.create(params$chapter_4, recursive = TRUE, showWarnings = FALSE)
dir.create(params$chapter_5, recursive = TRUE, showWarnings = FALSE)
dir.create(params$chapter_6, recursive = TRUE, showWarnings = FALSE)
```

```{r}
#| label: mermaid_helpers
#| include: false

format_count <- function(x) {
  ifelse(
    is.na(x),
    "NA",
    format(x, big.mark = ",", trim = TRUE)
  )
}

render_mermaid <- function(path, replacements) {
  template <- readLines(path)
  for (nm in names(replacements)) {
    template <- gsub(
      paste0("<<", nm, ">>"),
      replacements[[nm]],
      template,
      fixed = TRUE
    )
  }
  cat("```{mermaid}\n")
  cat(paste(template, collapse = "\n"))
  cat("\n```\n")
}
```


<p align="center">
`r sprintf("[![Version](https://img.shields.io/badge/DOI-%s-blue.svg)](#)", URLencode(rmarkdown::metadata$doi, reserved = TRUE))`
[![GitHub](https://img.shields.io/github/release/IPBES-Data/IPBES_SPC_Corpus.svg)](https://github.com/IPBES-Data/IPBES_SPC_Corpus)
[![License: CC BY 4.0](https://img.shields.io/badge/License-CC%20BY%204.0-lightgrey.svg)](https://creativecommons.org/licenses/by/4.0/) 
</p>

<p align="center">
`r sprintf("[![Version](https://img.shields.io/badge/Version-%s-blue.svg)](#)", URLencode(rmarkdown::metadata$version, reserved = TRUE))`
`r sprintf("[![Build](https://img.shields.io/badge/Build-%s-greene.svg)](#)", build)`
</p>

<!-- Part of the Data Management Report [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.10251349.svg)](https://doi.org/10.5281/zenodo.10251349) -->

# Disclaimer
<!-- This is a technical background document for the IPBES Thematic assessment of the underlying causes of biodiversity loss, determinants of transformative change and options for achieving the 2050 vision for biodiversity. It provides technical details and implementation settings for the data management report of the [Transformative Change Assessment Corpus and its usage](https://doi.org/10.5281/zenodo.10251349). The sole purpose of this document is to document the workflows used to produce statistics, figures and maps, to document the source of the data and to make the process transparent and reproducible. -->

# LLM Usage Disclosure

Code and charts in this project have been generated with the assistance of the codex LLM tools in Positron. All content and code is based on conceptuaisation by the authors and has been thoroughly reviewed and edited by humans afterwards.

# Contributors
## Assessment Experts

- xxx, yyy [![ORCID](./images/ORCID-iD_icon-16x16.png)](https://orcid.org/XXXXXXX)

## Data and Knowledge tsu



# Working Title
IPBES_SPC_Corpus

## Code repo

[Github repository](https://github.com/IPBES-Data/IPBES_SPC_Corpus){target="_blank"}


# Introduction

The literature search for the Spatial Planning and Connectivity assessment corpus was conducted using search terms provided by the experts and refined in co-operation with the IPBES task force for data and knowledge management.
The search was conducted using [OpenAlex](https://openalex.org), scripted from [R](https://cran.r-project.org) to use  the [OpenAlex API](https://docs.openalex.org). Search terms for the following searches were defined:

- **Spatial Planning and Connectivity**,
- **Nature / Environment**
- **additional search terms** for specific corpora

To assess the quality of the corpus, sets of key papers were selected by the experts to verify if these are in the corpus. 

The following terminology is used in this document:

- **Corpus**: A body of works as based on a search on [OpenAlex](https://openalex.org)
- **Spatial Planning and Connectivity Assessment Corpus**: Short: SPC corpus; The corpus resulting from the search terms TO BE ADDED
- **work**: terminology used for a single document in their dataset. Each work has a unique OpenAlex id, but not necessarily a DOI.

The following searches are conducted on Title and Abstract only to account for fluctuating availability of full text searches and make the search more focussed..

## Schematic Overview

This is a schematic overview of the search strategy. It is shown again in the Results section with the numbers of resulting hits.
### Overview

```{mermaid}
{{< include figures/overview.mmd >}}
```


### Chapter 1

```{mermaid}
{{< include figures/chapter1.mmd >}}
```


#### Search Terms

Click [chapter_1.yaml](input/search_terms/chapter_1.yaml){target="_blank" rel="noopener noreferrer"} to download

```{r}
params$search_terms$chapter_1 |>
  yaml::as.yaml() |>
  cat()
```


### Chapter 2

```{mermaid}
{{< include figures/chapter2.mmd >}}
```

#### Search Terms

Click [chapter_2.yaml](input/search_terms/chapter_2.yaml){target="_blank" rel="noopener noreferrer"} to download

```{r}
params$search_terms$chapter_2 |>
  yaml::as.yaml() |>
  cat()
```

Non implemented additional searches are:

- Click [chapter_2_add.yaml](input/search_terms/chapter_2_add.yaml){target="_blank" rel="noopener noreferrer"} to download
- Click [chapter_2_sdg.yaml](input/search_terms/chapter_2_sdg.yaml){target="_blank" rel="noopener noreferrer"} to download

### Chapter 3

```{mermaid}
{{< include figures/chapter3.mmd >}}
```

#### Search Terms

Click [chapter_3.yaml](input/search_terms/chapter_3.yaml){target="_blank" rel="noopener noreferrer"} to download

```{r}
params$search_terms$chapter_3 |>
  yaml::as.yaml() |>
  cat()
```


### Chapter 4

```{mermaid}
{{< include figures/chapter4.mmd >}}
```

#### Search Terms

Click [chapter_4.yaml](input/search_terms/chapter_4.yaml){target="_blank" rel="noopener noreferrer"} to download

```{r}
params$search_terms$chapter_4 |>
  yaml::as.yaml() |>
  cat()
```


### Chapter 5

```{mermaid}
{{< include figures/chapter5.mmd >}}
```

#### Search Terms

Click [chapter_5.yaml](input/search_terms/chapter_5.yaml){target="_blank" rel="noopener noreferrer"} to download

```{r}
params$search_terms$chapter_5 |>
  yaml::as.yaml() |>
  cat()
```


### Chapter 6

```{mermaid}
{{< include figures/chapter6.mmd >}}
```

#### Search Terms

Click [chapter_6.yaml](input/search_terms/chapter_6.yaml){target="_blank" rel="noopener noreferrer"} to download

```{r}
params$search_terms$chapter_6 |>
  yaml::as.yaml() |>
  cat()
```

Non implemented additional searches are:

- Click [chapter_6_r2.yaml](input/search_terms/chapter_6_r2.yaml){target="_blank" rel="noopener noreferrer"} to download


## Type Selsection

OpenAlex contains more then 270 million works of different types. The following table shows and explains the available types and highlights which are selected to be included in the SPC Corpus.


```{r}
#| label: openalex_work_types

params$types |>
  knitr::kable(
    caption = "OpenAlex Work Types and Inclusion in the SPC Corpus",
    booktabs = TRUE,
    align = c("l", "l", "l", "c")
  ) # |>
# kableExtra::kable_styling(
#     full_width = FALSE,
#     position = "left"
# )
```

<!-- 
## Search Terms {#sec-search_terms}

Here are the search terms used in this document. They were provided by the authors, and some adaptations were done by the tsu for data and knowledge management to adapt them to be suitable for a search in OpenAlex.
Will possibly be added later -->


# Methods

## SPC Corpus

### Assess of Individual Terms in spc and nature search terms

This assessment is done on the whole of the OpenAlex corpus and only filtered for types and *not* for the date range.

```{r}
#| label: searchterm_assessment_spc

fn <- file.path(params$output_dir, "searchterm_assessment_spcc.rds")

if (!file.exists(fn)) {
  result <- list(
    spc = assess_search_term_both(
      st = params$search_terms$spc_corpus$spc,
      and_term = stcompact(params$search_terms$spc_corpus$spc_corpus$nature),
      types = params$types_filter,
      verbose = TRUE
    ),
    nature = assess_search_term_both(
      st = params$search_terms$spc_corpus$nature,
      and_term = stcompact(params$search_terms$spc_corpus$spc_corpus$spc),
      types = params$types_filter,
      verbose = FALSE
    )
  ) |>
    saveRDS(fn)
}
```




### Get Key Paper

Here we get key papers in a parquet database which is partitioned by:

- `found_in`: the search term or openalex which is used as the filter, i.e. the key paper occurs in corpus which would result from the search term 
- `id_used`: the id used to testing,m either the OpenAlex id (id) or the doi (doi)
- `page`: only for processing reasons

No filtering, neither by type nor by publication year is done.

The other columns are as returned by the OpenAlex API.
```{r}
#| label: get_key_works_prep
#|

st <- list(
  spc = params$search_terms$spc_corpus$spc |>
    paste0(collapse = " "),
  nature = params$search_terms$spc_corpus$nature |>
    paste0(collapse = " ")
)
st$spcc <- paste0("(", st$spc, ") AND (", st$nature, ")")

dois <- params$key_papers$goldstandard$DOI[
  params$key_papers$goldstandard$DOI != ""
]
ids <- params$key_papers$goldstandard$openalex_id[
  params$key_papers$goldstandard$openalex_id != ""
]
```

```{r}
#| label: get_key_works_openalex
#|

fn <- file.path(params$keyworks, "parquet", "found_in=openalex")
if (!dir.exists(fn)) {
  ### KP in OpenAlex
  openalexPro::pro_query(
    doi = dois,
    chunk_limit = 50
  ) |>
    openalexPro::pro_request(
      output = file.path(fn, "..", "json_doi")
    ) |>
    openalexPro::pro_request_jsonl(
      output = file.path(fn, "..", "jsonl_doi"),
      delete_input = TRUE
    ) |>
    openalexPro::pro_request_jsonl_parquet(
      output = file.path(fn, "id_used=doi"),
      delete_input = TRUE
    )

  openalexPro::pro_query(
    id = ids,
    multiple_id = TRUE,
    chunk_limit = 50
  ) |>
    openalexPro::pro_request(
      output = file.path(fn, "..", "json_oa_id")
    ) |>
    openalexPro::pro_request_jsonl(
      output = file.path(fn, "..", "jsonl_oa_id"),
      delete_input = TRUE
    ) |>
    openalexPro::pro_request_jsonl_parquet(
      output = file.path(fn, "id_used=oa_id"),
      delete_input = TRUE
    )
}
```

```{r}
#| label: get_key_works_spc
#|

fn <- file.path(params$keyworks, "parquet", "found_in=spc")
if (!dir.exists(fn)) {
  openalexPro::pro_query(
    title_and_abstract.search = st$spc,
    doi = dois,
    chunk_limit = 25
  ) |>
    openalexPro::pro_request(
      output = file.path(fn, "..", "json_doi")
    ) |>
    openalexPro::pro_request_jsonl(
      output = file.path(fn, "..", "jsonl_doi"),
      delete_input = TRUE
    ) |>
    openalexPro::pro_request_jsonl_parquet(
      output = file.path(fn, "id_used=doi"),
      delete_input = TRUE
    )

  openalexPro::pro_query(
    title_and_abstract.search = st$spc,
    id = ids,
    multiple_id = TRUE,
    chunk_limit = 25
  ) |>
    openalexPro::pro_request(output = file.path(fn, "json_oa_id")) |>
    openalexPro::pro_request_jsonl(
      output = file.path(fn, "jsonl_oa_id"),
      delete_input = TRUE
    ) |>
    openalexPro::pro_request_jsonl_parquet(
      output = file.path(fn, "id_used=oa_id"),
      delete_input = TRUE
    )
}
```

```{r}
#| label: get_key_works_nature
#|

fn <- file.path(params$keyworks, "parquet", "found_in=nature")
if (!dir.exists(fn)) {
  ### KP in nature
  openalexPro::pro_query(
    title_and_abstract.search = st$nature,
    doi = dois,
    chunk_limit = 25
  ) |>
    openalexPro::pro_request(output = file.path(fn, "json_doi")) |>
    openalexPro::pro_request_jsonl(
      output = file.path(fn, "jsonl_doi"),
      delete_input = TRUE
    ) |>
    openalexPro::pro_request_jsonl_parquet(
      output = file.path(fn, "id_used=doi"),
      delete_input = TRUE
    )

  openalexPro::pro_query(
    title_and_abstract.search = st$nature,
    id = ids,
    multiple_id = TRUE,
    chunk_limit = 25
  ) |>
    openalexPro::pro_request(output = file.path(fn, "json_oa_id")) |>
    openalexPro::pro_request_jsonl(
      output = file.path(fn, "jsonl_oa_id"),
      delete_input = TRUE
    ) |>
    openalexPro::pro_request_jsonl_parquet(
      output = file.path(fn, "id_used=oa_id"),
      delete_input = TRUE
    )
}
```

```{r}
#| label: get_key_works_spcc
#|

fn <- file.path(params$keyworks, "parquet", "found_in=spcc")
if (!dir.exists(fn)) {
  ### KP in spcc
  openalexPro::pro_query(
    title_and_abstract.search = st$spcc,
    doi = params$key_papers$goldstandard$DOI[
      params$key_papers$goldstandard$DOI != ""
    ],
    chunk_limit = 15
  ) |>
    openalexPro::pro_request(output = file.path(fn, "json_doi")) |>
    openalexPro::pro_request_jsonl(
      output = file.path(fn, "jsonl_doi"),
      delete_input = TRUE
    ) |>
    openalexPro::pro_request_jsonl_parquet(
      output = file.path(fn, "id_used=doi"),
      delete_input = TRUE
    )

  openalexPro::pro_query(
    title_and_abstract.search = st$spcc,
    id = params$key_papers$goldstandard$openalex_id[
      params$key_papers$goldstandard$openalex_id != ""
    ],
    multiple_id = TRUE,
    chunk_limit = 25
  ) |>
    openalexPro::pro_request(output = file.path(fn, "json_oa_id")) |>
    openalexPro::pro_request_jsonl(
      output = file.path(fn, "jsonl_oa_id"),
      delete_input = TRUE
    ) |>
    openalexPro::pro_request_jsonl_parquet(
      output = file.path(fn, "id_used=oa_id"),
      delete_input = TRUE
    )
}
```

### Keypaper in Search Terms

The in the previous step retrieved works are analysed here to get a table which shows where the key paper occur.


```{r}
#| label: kp_found_in

fn <- file.path(params$keyworks, "kp_found_in.rds")
if (!file.exists(fn)) {
  arrow::open_dataset(file.path(params$keyworks, "parquet")) |>
    dplyr::select(
      id,
      doi,
      type,
      found_in,
      title,
      citation
    ) |>
    dplyr::group_by(id, doi, title, citation, type) |>
    dplyr::summarise(
      in_openalex = base::max(found_in == "openalex", na.rm = TRUE),
      in_spc = base::max(found_in == "spc", na.rm = TRUE),
      in_nature = base::max(found_in == "nature", na.rm = TRUE),
      in_spcc = base::max(found_in == "spcc", na.rm = TRUE),
      .groups = "drop"
    ) |>
    dplyr::collect() |>
    saveRDS(fn)
}

```


### Get Numbers from OpenAlex of the Search Terms

These data is gathered from OpenAlex directly, not downloaded any works. The data is used to assess the quality of the TCA Corpus.

The query contains:
- the search term (nature, spc, spcc)
- the types selected (`r paste(params$types_filter, collapse = ", ")`)
- the date range (from `r params$publication_date$from` to `r params$publication_date$to`)

The following counts are retrieved:

#### Overall hits

```{r}
#| label: get_st_hits
#|

fn <- file.path(params$corpus, "st_hits.rds")
if (!file.exists(fn)) {
  st <- list(
    spc = params$search_terms$spc_corpus$spc |>
      paste0(collapse = " "),
    nature = params$search_terms$spc_corpus$nature |>
      paste0(collapse = " ")
  )
  st$spcc <- paste0("(", st$spc, ") AND (", st$nature, ")")

  queries <- lapply(
    st,
    function(s) {
      openalexPro::pro_query(
        title_and_abstract.search = s,
        type = params$types_filter,
        from_publication_date = params$publication_date$from,
        to_publication_date = params$publication_date$to
      )
    }
  )
  queries$openalex <- openalexPro::pro_query(
    type = params$types_filter,
    from_publication_date = params$publication_date$from,
    to_publication_date = params$publication_date$to,
  )

  pbapply::pblapply(
    queries,
    function(query) {
      query |>
        openalexR::oa_request(
          count_only = TRUE,
          verbose = TRUE
        ) |>
        unlist()
    }
  ) |>
    do.call(what = cbind) |>
    t() |>
    as.data.frame() |>
    dplyr::select(count) |>
    saveRDS(file = fn)
}
```

#### Counts per Language

```{r}
#| label: get_st_languages
#|

fn <- file.path(params$corpus, "st_languages.rds")
if (!file.exists(fn)) {
  st <- list(
    spc = params$search_terms$spc_corpus$spc |>
      paste0(collapse = " "),
    nature = params$search_terms$spc_corpus$nature |>
      paste0(collapse = " ")
  )
  st$spcc <- paste0("(", st$spc, ") AND (", st$nature, ")")

  queries <- lapply(
    st,
    function(s) {
      openalexPro::pro_query(
        title_and_abstract.search = s,
        type = params$types_filter,
        from_publication_date = params$publication_date$from,
        to_publication_date = params$publication_date$to,
        group_by = "language"
      )
    }
  )
  queries$openalex <- openalexPro::pro_query(
    type = params$types_filter,
    from_publication_date = params$publication_date$from,
    to_publication_date = params$publication_date$to,
    group_by = "language"
  )

  pbapply::pblapply(
    queries,
    function(query) {
      query |>
        openalexR::oa_request(
          verbose = TRUE
        ) |>
        dplyr::bind_rows()
    }
  ) |>
    dplyr::bind_rows(.id = "source") |>
    dplyr::select(source, language = key_display_name, count) |>
    tidyr::pivot_wider(
      names_from = source,
      values_from = count,
      names_prefix = "count_",
      values_fill = 0
    ) |>
    dplyr::select(
      language,
      count_openalex,
      count_spc,
      count_nature,
      count_spcc
    ) |>
    dplyr::arrange(language) |>
    saveRDS(file = fn)
}
```

#### Counts per Publication Year
```{r}
#| label: get_st_years
#| #|

fn <- file.path(params$corpus, "st_years.rds")
if (!file.exists(fn)) {
  st <- list(
    spc = params$search_terms$spc_corpus$spc |>
      paste0(collapse = " "),
    nature = params$search_terms$spc_corpus$nature |>
      paste0(collapse = " ")
  )
  st$spcc <- paste0("(", st$spc, ") AND (", st$nature, ")")

  queries <- lapply(
    st,
    function(s) {
      openalexPro::pro_query(
        title_and_abstract.search = s,
        type = params$types_filter,
        from_publication_date = params$publication_date$from,
        to_publication_date = params$publication_date$to,
        group_by = "publication_year"
      )
    }
  )
  queries$openalex <- openalexPro::pro_query(
    type = params$types_filter,
    from_publication_date = params$publication_date$from,
    to_publication_date = params$publication_date$to,
    group_by = "publication_year"
  )

  result <- pbapply::pblapply(
    queries,
    function(query) {
      query |>
        openalexR::oa_request(
          verbose = TRUE
        ) |>
        dplyr::bind_rows()
    }
  ) |>
    dplyr::bind_rows(.id = "source") |>
    dplyr::select(source, year = key, count) |>
    dplyr::mutate(year = base::as.integer(year)) |>
    tidyr::pivot_wider(
      names_from = source,
      values_from = count,
      names_prefix = "count_",
      values_fill = 0
    ) |>
    dplyr::select(
      year,
      count_openalex,
      count_spc,
      count_nature,
      count_spcc
    ) |>
    dplyr::arrange(dplyr::desc(year)) |>
    saveRDS(file = fn)
}
```


## Chapter 1

```{r}
#| label: get_st_hits_chapter_1

# params$search_terms$chapter_1

fn <- file.path(params$chapter_1, "st_hits.rds")
if (!file.exists(fn)) {
  spcc <- paste0(
    "(",
    stcompact(params$search_terms$spc_corpus$spc),
    ") AND (",
    stcompact(params$search_terms$spc_corpus$nature),
    ")"
  )
  queries <- lapply(
    params$search_terms$chapter_1,
    function(s) {
      openalexPro::pro_query(
        title_and_abstract.search = paste0(
          "(",
          spcc,
          ") AND (",
          stcompact(s),
          ")"
        ),
        type = params$types_filter,
        from_publication_date = params$publication_date$from,
        to_publication_date = params$publication_date$to
      )
    }
  )

  result <- pbapply::pblapply(
    queries,
    function(query) {
      query |>
        openalexR::oa_request(
          count_only = TRUE,
          verbose = TRUE
        ) |>
        unlist()
    }
  ) |>
    do.call(what = cbind) |>
    t() |>
    as.data.frame() |>
    dplyr::select(count)

  rownames(result) <- names(queries)
  saveRDS(result, file = fn)
}
```

## Chapter 2

```{r}
#| label: get_st_hits_chapter_2

fn <- file.path(params$chapter_2, "st_hits.rds")
if (!file.exists(fn)) {
  spcc <- paste0(
    "(",
    stcompact(params$search_terms$spc_corpus$spc),
    ") AND (",
    stcompact(params$search_terms$spc_corpus$nature),
    ")"
  ) |>
    stcompact()

  queries <- lapply(
    params$search_terms$chapter_2,
    function(section) {
      lapply(
        section,
        function(s) {
          openalexPro::pro_query(
            title_and_abstract.search = paste0(
              "(",
              spcc,
              ") AND (",
              stcompact(s),
              ")"
            ),
            type = params$types_filter,
            from_publication_date = params$publication_date$from,
            to_publication_date = params$publication_date$to
          )
        }
      )
    }
  )

  result <- lapply(
    names(queries),
    function(sect_nm) {
      result <- lapply(
        names(queries[[sect_nm]]),
        function(nm) {
          message("Retrieving ", sect_nm, " - ", nm, " ...")
          result <- c(
            count = NA_integer_,
            db_response_time_ms = NA_integer_,
            page = NA_integer_,
            per_page = NA_integer_
          )
          try(
            result <- queries[[sect_nm]][nm] |>
              openalexR::oa_request(
                count_only = TRUE,
                verbose = TRUE
              ) |>
              unlist(),
            silent = FALSE
          )
          return(result)
        }
      ) |>
        do.call(what = cbind) |>
        t() |>
        as.data.frame() |>
        dplyr::select(count)
      browser()
      rownames(result) <- names(queries[[sect_nm]])
      return(result)
    }
  )
  names(result) <- names(queries)

  saveRDS(result, file = fn)
}

# fn <- file.path(params$chapter_2, "st_hits.rds")
# if (!file.exists(fn)) {
#   spcc <- paste0(
#     "(",
#     stcompact(params$search_terms$spc_corpus$spc),
#     ") AND (",
#     stcompact(params$search_terms$spc_corpus$nature),
#     ")"
#   )
#   queries <- lapply(
#     params$search_terms$chapter_2,
#     function(s) {
#       openalexPro::pro_query(
#         title_and_abstract.search = paste0(
#           "(",
#           spcc,
#           ") AND (",
#           stcompact(s),
#           ")"
#         ),
#         type = params$types_filter,
#         from_publication_date = params$publication_date$from,
#         to_publication_date = params$publication_date$to
#       )
#     }
#   )

#   result <- pbapply::pblapply(
#     queries,
#     function(query) {
#       query |>
#         openalexR::oa_request(
#           count_only = TRUE,
#           verbose = TRUE
#         ) |>
#         unlist()
#     }
#   ) |>
#     do.call(what = cbind) |>
#     t() |>
#     as.data.frame() |>
#     dplyr::select(count)

#   rownames(result) <- names(queries)
#   saveRDS(result, file = fn)
# }
```


## Chapter 3

```{r}
#| label: get_st_hits_chapter_3
#| eval: true

fn <- file.path(params$chapter_3, "st_hits.rds")
if (!file.exists(fn)) {
  spcc <- paste0(
    "(",
    stcompact(params$search_terms$spc_corpus$spc),
    ") AND (",
    stcompact(params$search_terms$spc_corpus$nature),
    ")"
  )
  queries <- lapply(
    params$search_terms$chapter_3,
    function(s) {
      result <- c(
        count = NA_integer_,
        db_response_time_ms = NA_integer_,
        page = NA_integer_,
        per_page = NA_integer_
      )
      try(
        result <- openalexPro::pro_query(
          title_and_abstract.search = paste0(
            "(",
            spcc,
            ") AND (",
            stcompact(s),
            ")"
          ),
          type = params$types_filter,
          from_publication_date = params$publication_date$from,
          to_publication_date = params$publication_date$to
        ),
        silent = FALSE
      )
    }
  )

  result <- pbapply::pblapply(
    queries,
    function(query) {
      result <- c(
        count = NA_integer_,
        db_response_time_ms = NA_integer_,
        page = NA_integer_,
        per_page = NA_integer_
      )
      try(
        result <- query |>
          openalexR::oa_request(
            count_only = TRUE,
            verbose = TRUE
          ) |>
          unlist()
      )
    }
  ) |>
    do.call(what = cbind) |>
    t() |>
    as.data.frame() |>
    dplyr::select(count)
  rownames(result) <- names(queries)
  saveRDS(result, file = fn)
}
```

## Chapter 4

```{r}
#| label: get_st_hits_chapter_4

fn <- file.path(params$chapter_4, "st_hits.rds")
if (!file.exists(fn)) {
  spcc <- paste0(
    "(",
    stcompact(params$search_terms$spc_corpus$spc),
    ") AND (",
    stcompact(params$search_terms$spc_corpus$nature),
    ")"
  )
  queries <- lapply(
    params$search_terms$chapter_4,
    function(s) {
      openalexPro::pro_query(
        title_and_abstract.search = paste0(
          "(",
          spcc,
          ") AND (",
          stcompact(s),
          ")"
        ),
        type = params$types_filter,
        from_publication_date = params$publication_date$from,
        to_publication_date = params$publication_date$to
      )
    }
  )

  result <- pbapply::pblapply(
    queries,
    function(query) {
      query |>
        openalexR::oa_request(
          count_only = TRUE,
          verbose = TRUE
        ) |>
        unlist()
    }
  ) |>
    do.call(what = cbind) |>
    t() |>
    as.data.frame() |>
    dplyr::select(count)
  rownames(result) <- names(queries)
  saveRDS(result, file = fn)
}
```


## Chapter 5

```{r}
#| label: get_st_hits_chapter_5

fn <- file.path(params$chapter_5, "st_hits.rds")
if (!file.exists(fn)) {
  spcc <- paste0(
    "(",
    stcompact(params$search_terms$spc_corpus$spc),
    ") AND (",
    stcompact(params$search_terms$spc_corpus$nature),
    ")"
  ) |>
    stcompact()

  queries <- lapply(
    params$search_terms$chapter_5,
    function(section) {
      lapply(
        section,
        function(s) {
          openalexPro::pro_query(
            title_and_abstract.search = paste0(
              "(",
              spcc,
              ") AND (",
              stcompact(s),
              ")"
            ),
            type = params$types_filter,
            from_publication_date = params$publication_date$from,
            to_publication_date = params$publication_date$to
          )
        }
      )
    }
  )

  result <- lapply(
    names(queries),
    function(sect_nm) {
      result <- lapply(
        names(queries[[sect_nm]]),
        function(nm) {
          message("Retrieving ", sect_nm, " - ", nm, " ...")
          result <- c(
            count = NA_integer_,
            db_response_time_ms = NA_integer_,
            page = NA_integer_,
            per_page = NA_integer_
          )
          try(
            result <- queries[[sect_nm]][nm] |>
              openalexR::oa_request(
                count_only = TRUE,
                verbose = TRUE
              ) |>
              unlist(),
            silent = FALSE
          )
          return(result)
        }
      ) |>
        do.call(what = cbind) |>
        t() |>
        as.data.frame() |>
        dplyr::select(count)
      browser()
      rownames(result) <- names(queries[[sect_nm]])
      return(result)
    }
  )
  names(result) <- names(queries)

  saveRDS(result, file = fn)
}
```


## Chapter 6


```{r}
#| label: get_st_hits_chapter_6
#| eval: true

fn <- file.path(params$chapter_6, "st_hits.rds")
if (!file.exists(fn)) {
  spcc <- paste0(
    "(",
    stcompact(params$search_terms$spc_corpus$spc),
    ") AND (",
    stcompact(params$search_terms$spc_corpus$nature),
    ")"
  )
  queries <- lapply(
    params$search_terms$chapter_6,
    function(s) {
      openalexPro::pro_query(
        title_and_abstract.search = paste0(
          "(",
          spcc,
          ") AND (",
          stcompact(s),
          ")"
        ),
        type = params$types_filter,
        from_publication_date = params$publication_date$from,
        to_publication_date = params$publication_date$to
      )
    }
  )

  pbapply::pblapply(
    queries,
    function(query) {
      query |>
        openalexR::oa_request(
          count_only = TRUE,
          verbose = TRUE
        ) |>
        unlist()
    }
  ) |>
    do.call(what = cbind) |>
    t() |>
    as.data.frame() |>
    dplyr::select(count) |>
    saveRDS(file = fn)
}
```


# Results

## Assessment of Search Terms

The individual terms are assessed with the second term as AND, e,g. each individual term in spc is assessed with `AND nature`. In addition, 

### SPC Term

```{r}
#| label: spc_term_assessment_table

readRDS(file.path(params$output, "searchterm_assessment_spcc.rds"))$spc |>
  dplyr::arrange(desc(count)) |>
  dplyr::mutate(
    count = format(count, big.mark = ","),
    count_excl = format(count_excl, big.mark = ","),
  ) |>
  knitr::kable(format = "html", escape = FALSE)
```

### Nature Term

```{r}
#| label: nature_term_assessment_table

readRDS(file.path(params$output, "searchterm_assessment_spcc.rds"))$nature |>
  dplyr::arrange(desc(count)) |>
  dplyr::mutate(
    count = format(count, big.mark = ","),
    count_excl = format(count_excl, big.mark = ","),
  ) |>
  knitr::kable(format = "html", escape = FALSE)
```

## Keypaper in Corpus

No filtering, neither by type nor by publication year is done. Therefore, the pure search terms are evaluated. 
*If a paper is included in this table, doex not mean it is included in the final SPC Corpus due to filtering by dates and types!*

```{r}
#| label: kp_in_corpus_table

readRDS(file.path(params$keyworks, "kp_found_in.rds")) |>
  dplyr::mutate(
    id_display = sub("^.*/(W[0-9]+)$", "\\1", id),
    id = sprintf("<a href=\"%s\" target=\"_blank\">%s</a>", id, id_display),
    doi_display = sub("^https://doi.org/", "\\1", doi),
    doi = sprintf("<a href=\"%s\" target=\"_blank\">%s</a>", doi, doi_display)
  ) |>
  dplyr::arrange(
    in_spcc,
    in_spc,
    in_nature,
    in_openalex
  ) |>
  dplyr::mutate(
    dplyr::across(
      dplyr::starts_with("in_"),
      ~ dplyr::case_when(
        .x ~ '<b style="color:#008000;">☑</b>', # green bold checkbox
        !.x ~ '<b style="color:#cc0000;">☐</b>' # red bold empty checkbox
      )
    )
  ) |>
  dplyr::select(
    id,
    doi,
    citation,
    in_spcc,
    in_spc,
    in_nature,
    in_openalex
  ) |>
  knitr::kable(format = "html", escape = FALSE)
```

## SPC Corpus Measures and Numbers

These data is gathered from OpenAlex directly, not downloaded any works. The data is used to assess the quality of the TCA Corpus.

The query contains:
- the search term (nature, spc, spcc)
- the types selected (`r paste(params$types_filter, collapse = ", ")`)
- the date range (from `r params$publication_date$from` to `r params$publication_date$to`)

### Overall counts

```{r}
#| label: st_hits_table

readRDS(file.path(params$corpus, "st_hits.rds")) |>
  dplyr::mutate(
    count = format(count, big.mark = ",")
  ) |>
  knitr::kable(format = "html", escape = FALSE)
```

```{r}
#| label: overview_counts_mermaid
#| results: 'asis'

corpus_counts <- readRDS(file.path(params$corpus, "st_hits.rds"))

render_mermaid(
  file.path("figures", "overview.mmd"),
  list(
    SPC_LIST = format_count(corpus_counts[["spc", "count"]]),
    NATURE_LIST = format_count(corpus_counts[["nature", "count"]]),
    BASE_QUERY = format_count(corpus_counts[["spcc", "count"]])
  )
)
```

### Publication Years

```{r}
#| label: st_hits_years

readRDS(file.path(params$corpus, "st_years.rds")) |>
  dplyr::mutate(
    dplyr::across(
      dplyr::starts_with("count_"),
      ~ base::format(.x, big.mark = ",")
    )
  ) |>
  knitr::kable(format = "html", escape = FALSE)
```

This graph only shows the relative nuymber of publications per year to identify different trends.

```{r}
#| label: st_years_plot

readRDS(file.path(params$corpus, "st_years.rds")) |>
  tidyr::pivot_longer(
    cols = dplyr::starts_with("count_"),
    names_to = "source",
    values_to = "count",
    names_prefix = "count_"
  ) |>
  # scale each source so its total sum is 1
  dplyr::group_by(source) |>
  dplyr::mutate(
    total_count = base::sum(count, na.rm = TRUE),
    count = dplyr::if_else(total_count > 0, count / total_count, 0)
  ) |>
  dplyr::ungroup() |>
  dplyr::select(-total_count) |>
  ggplot2::ggplot(ggplot2::aes(x = year, y = count, color = source)) +
  ggplot2::geom_line(linewidth = 1) +
  ggplot2::geom_point(size = 1.5) +
  ggplot2::scale_y_continuous(
    labels = scales::label_percent(accuracy = 1),
    expand = ggplot2::expansion(mult = c(0.02, 0.06))
  ) +
  ggplot2::labs(
    x = "Year",
    y = "Share of total works (sum-scaled per source)",
    color = "Source",
    title = "Publications per year by source (each source sums to 1)"
  ) +
  ggplot2::theme_minimal(base_size = 14) +
  ggplot2::theme(
    legend.position = "bottom",
    panel.grid.minor = ggplot2::element_blank()
  )
```

### Language

```{r}
#| label: st_languages_table

readRDS(file.path(params$corpus, "st_languages.rds")) |>
  dplyr::mutate(
    dplyr::across(
      dplyr::starts_with("count_"),
      ~ base::format(.x, big.mark = ",")
    )
  ) |>
  knitr::kable(format = "html", escape = FALSE)
```

This graph only shows the relative number of publications per year to identify different trends.

```{r}
#| label: st_language_plot

readRDS(file.path(params$corpus, "st_languages.rds")) |>
  # keep top 15 languages by total (before scaling)
  dplyr::mutate(
    total = count_openalex + count_spc + count_nature + count_spcc
  ) |>
  dplyr::slice_max(total, n = 15) |>
  dplyr::arrange(dplyr::desc(total)) |>
  # fix display order so largest stays on top
  dplyr::mutate(language = factor(language, levels = rev(language))) |>
  dplyr::select(-total) |>
  # reshape wide → long
  tidyr::pivot_longer(
    cols = dplyr::starts_with("count_"),
    names_to = "source",
    values_to = "count",
    names_prefix = "count_"
  ) |>
  # scale so each source sums to 1
  dplyr::group_by(source) |>
  dplyr::mutate(
    total_source = base::sum(count, na.rm = TRUE),
    count = dplyr::if_else(total_source > 0, count / total_source, 0)
  ) |>
  dplyr::ungroup() |>
  dplyr::select(-total_source) |>
  ggplot2::ggplot(ggplot2::aes(x = language, y = count, fill = source)) +
  ggplot2::geom_col(position = "dodge") +
  ggplot2::coord_flip() +
  ggplot2::scale_y_continuous(
    labels = scales::label_percent(accuracy = 1),
    expand = ggplot2::expansion(mult = c(0, 0.05))
  ) +
  ggplot2::labs(
    x = "Language",
    y = "Share of total works within each source",
    fill = "Source",
    title = "Publications by language (top 15), scaled so each source sums to 1"
  ) +
  ggplot2::theme_minimal(base_size = 14) +
  ggplot2::theme(
    legend.position = "bottom",
    panel.grid.minor = ggplot2::element_blank()
  )
```


## Individual Chapter

Here we show the sub-searches for the individual chapters. In the tables indicating the number, an `NA` value indicates that the search string was to long (most likely) or any other error occured in the search. The same applies when an error message is given. 

### Chapter 1

```{r}
#| label: chapter_1_st_hits

ch1_hits <- readRDS(file.path(params$chapter_1, "st_hits.rds"))

ch1_counts <- setNames(ch1_hits$count, rownames(ch1_hits))

ch1_hits |>
  dplyr::mutate(count = format_count(count)) |>
  knitr::kable(
    col.names = c("Count"),
    align = "r"
  )
```

```{r}
#| label: chapter_1_mermaid
#| results: 'asis'

render_mermaid(
  file.path("figures", "chapter1.mmd"),
  c(
    C1_1 = format_count(ch1_counts[["Set 1"]]),
    C1_2 = format_count(ch1_counts[["Set 2"]]),
    C1_3 = format_count(ch1_counts[["Set 3"]]),
    C1_4 = format_count(ch1_counts[["Set 4"]]),
    C1_5 = format_count(ch1_counts[["Set 5"]]),
    C1_6 = format_count(ch1_counts[["Set 6"]]),
    C1_7 = format_count(ch1_counts[["Set 7"]])
  )
)
```

### Chapter 2

```{r}
#| label: chapter_2_st_hits

ch2_hits <- readRDS(file.path(params$chapter_2, "st_hits.rds"))

ch2_counts <- lapply(ch2_hits, function(df) {
  setNames(df$count, rownames(df))
})

do.call(
  rbind,
  lapply(names(ch2_hits), function(sect_nm) {
    df <- ch2_hits[[sect_nm]]
    df$section <- sect_nm
    df$set <- rownames(df)
    rownames(df) <- NULL
    df[,
      c("section", "set", setdiff(names(df), c("section", "set"))),
      drop = FALSE
    ]
  })
) |>
  dplyr::mutate(
    count = format_count(count)
  ) |>
  knitr::kable(
    col.names = c("Section", "Set", "Count"),
    align = c("c", "c", "r")
  )
```

```{r}
#| label: chapter_2_mermaid
#| results: 'asis'

ch2_gbf <- ch2_counts[["GBF"]]
ch2_targets <- ch2_counts[["Targets"]]
ch2_rel <- ch2_counts[["Related to spatial planning process"]]
ch2_nexus <- ch2_counts[["Nexus"]]

fmt_gbf <- function(name) format_count(ch2_gbf[[name]])
fmt_target <- function(name) format_count(ch2_targets[[name]])
fmt_rel <- function(name) format_count(ch2_rel[[name]])
fmt_nexus <- function(name) format_count(ch2_nexus[[name]])

render_mermaid(
  file.path("figures", "chapter2.mmd"),
  c(
    GBF_Urban = fmt_gbf("GBF-1 - Urban"),
    GBF_Rural = fmt_gbf("GBF-1 - Rural"),
    GBF_Fresh = fmt_gbf("GBF-1 - Freshwater"),
    GBF_Marine = fmt_gbf("GBF-1 - Marine"),
    GBF_Restore = fmt_gbf("GBF - 2 (Ecosystem restoration)"),
    T3 = fmt_target("Target 3 (Protected areas / conservation coverage)"),
    T4 = fmt_target("Target 4 (Species extinction & genetic diversity)"),
    T5 = fmt_target("Target 5 (Wild species trade & use)"),
    T6 = fmt_target("Target 6 (Invasive alien species)"),
    T7 = fmt_target("Target 7 (Pollution)"),
    T8 = fmt_target("Target 8 (Climate change & resilience)"),
    T9 = fmt_target("Target 9 (Wild species management & use)"),
    T10 = fmt_target(
      "Target 10 (Sustainability in agriculture, aquaculture, forestry & fisheries)"
    ),
    T11 = fmt_target(
      "Target 11 (Nature\u2019s contributions to people / ecosystem services)"
    ),
    T12 = fmt_target("Target 12 (Green & blue spaces, urban planning)"),
    T13 = fmt_target("Target 13 (Genetic resources & benefit sharing)"),
    T14 = fmt_target("Target 14 (Biodiversity integration in decision-making)"),
    T15 = fmt_target(
      "Target 15 (Business & financial institutions disclosure & risk)"
    ),
    T16 = fmt_target("Target 16 (Sustainable consumption)"),
    T17 = fmt_target("Target 17 (Biosafety)"),
    T18 = fmt_target("Target 18 (Harmful incentives / subsidies)"),
    T19 = fmt_target("Target 19 (Finance mobilisation)"),
    T20 = fmt_target("Target 20 (Capacity building, technology & cooperation)"),
    T21 = fmt_target("Target 21 (Data, knowledge & monitoring)"),
    T22 = fmt_target("Target 22 (Participation & inclusion)"),
    T23 = fmt_target("Target 23 (Gender equality)"),
    REL = fmt_rel("Set Related"),
    Nexus_Water = fmt_nexus("Water"),
    Nexus_Food = fmt_nexus("Food"),
    Nexus_Health = fmt_nexus("Health"),
    Nexus_Climate = fmt_nexus("Climate")
  )
)
```

### Chapter 3

```{r}
#| label: chapter_3_st_hits

ch3_hits <- readRDS(file.path(params$chapter_3, "st_hits.rds"))

ch3_counts <- setNames(ch3_hits$count, rownames(ch3_hits))

ch3_hits |>
  dplyr::mutate(count = format_count(count)) |>
  knitr::kable(
    col.names = c("Count"),
    align = "r"
  )
```

```{r}
#| label: chapter_3_mermaid
#| results: 'asis'

render_mermaid(
  file.path("figures", "chapter3.mmd"),
  c(
    C3_1 = format_count(ch3_counts[["Set 1"]]),
    C3_2 = format_count(ch3_counts[["Set 2"]]),
    C3_3 = format_count(ch3_counts[["Set 3"]]),
    C3_4 = format_count(ch3_counts[["Set 4"]]),
    C3_5 = format_count(ch3_counts[["Set 5"]]),
    C3_6 = format_count(ch3_counts[["Set 6"]]),
    C3_7 = format_count(ch3_counts[["Set 7"]]),
    C3_8 = format_count(ch3_counts[["Set 8"]]),
    C3_9 = format_count(ch3_counts[["Set 9"]]),
    C3_10 = format_count(ch3_counts[["Set 10"]])
  )
)
```

### Chapter 4

```{r}
#| label: chapter_4_st_hits

ch4_hits <- readRDS(file.path(params$chapter_4, "st_hits.rds"))

ch4_counts <- setNames(ch4_hits$count, rownames(ch4_hits))

ch4_hits |>
  dplyr::mutate(count = format_count(count)) |>
  knitr::kable(
    col.names = c("Count"),
    align = "r"
  )
```

```{r}
#| label: chapter_4_mermaid
#| results: 'asis'

render_mermaid(
  file.path("figures", "chapter4.mmd"),
  c(
    C4_1 = format_count(ch4_counts[["Set 1"]]),
    C4_2 = format_count(ch4_counts[["Set 2"]]),
    C4_3 = format_count(ch4_counts[["Set 3"]]),
    C4_4 = format_count(ch4_counts[["Set 4"]]),
    C4_5 = format_count(ch4_counts[["Set 5"]]),
    C4_6 = format_count(ch4_counts[["Set 6"]]),
    C4_7 = format_count(ch4_counts[["Set 7"]]),
    C4_8 = format_count(ch4_counts[["Set 8"]])
  )
)
```

### Chapter 5

```{r}
#| label: chapter_5_st_hits

ch5_hits <- readRDS(file.path(params$chapter_5, "st_hits.rds"))

ch5_counts <- lapply(ch5_hits, function(df) {
  setNames(df$count, rownames(df))
})

do.call(
  rbind,
  lapply(names(ch5_hits), function(sect_nm) {
    df <- ch5_hits[[sect_nm]]
    df$section <- sect_nm
    df$set <- rownames(df)
    rownames(df) <- NULL
    df[,
      c("section", "set", setdiff(names(df), c("section", "set"))),
      drop = FALSE
    ]
  })
) |>
  dplyr::mutate(
    count = format_count(count)
  ) |>
  knitr::kable(
    col.names = c("Section", "Set", "Count"),
    align = c("c", "c", "r")
  )

```

```{r}
#| label: chapter_5_mermaid
#| results: 'asis'

fmt_ch5 <- function(section, set) {
  format_count(ch5_counts[[section]][[set]])
}

render_mermaid(
  file.path("figures", "chapter5.mmd"),
  c(
    C5_1 = fmt_ch5("Sections 1 and 2", "Set 1"),
    C5_2 = fmt_ch5("Sections 1 and 2", "Set 2"),
    C5_3 = fmt_ch5("Sections 1 and 2", "Set 3"),
    C5_4 = fmt_ch5("Sections 1 and 2", "Set 4"),
    C5_5 = fmt_ch5("Sections 1 and 2", "Set 5"),
    C5_3a = fmt_ch5("Section 3", "Set 1"),
    C5_3b = fmt_ch5("Section 3", "Set 2"),
    C5_3c = fmt_ch5("Section 3", "Set 3"),
    C5_4a = fmt_ch5("Section 4", "Set 1"),
    C5_4b = fmt_ch5("Section 4", "Set 2"),
    C5_4c = fmt_ch5("Section 4", "Set 3"),
    C5_5a = fmt_ch5("Section 5", "Set 1"),
    C5_5b = fmt_ch5("Section 5", "Set 2"),
    C5_5c = fmt_ch5("Section 5", "Set 3"),
    C5_5d = fmt_ch5("Section 5", "Set 4"),
    C5_6a = fmt_ch5("Section 6", "Set 1"),
    C5_6b = fmt_ch5("Section 6", "Set 2"),
    C5_6c = fmt_ch5("Section 6", "Set 3"),
    C5_6d = fmt_ch5("Section 6", "Set 4"),
    CC1 = fmt_ch5("Cross-cutting sets", "Set 1"),
    CC2 = fmt_ch5("Cross-cutting sets", "Set 2")
  )
)
```

### Chapter 6

```{r}
#| label: chapter_6_st_hits

ch6_hits <- readRDS(file.path(params$chapter_6, "st_hits.rds"))

ch6_counts <- setNames(ch6_hits$count, rownames(ch6_hits))

ch6_hits |>
  dplyr::mutate(count = format_count(count)) |>
  knitr::kable(
    col.names = c("Count"),
    align = "r"
  )
```

```{r}
#| label: chapter_6_mermaid
#| results: 'asis'

render_mermaid(
  file.path("figures", "chapter6.mmd"),
  c(
    C6_1 = format_count(ch6_counts[["Set 1"]]),
    C6_2 = format_count(ch6_counts[["Set 2"]]),
    C6_3 = format_count(ch6_counts[["Set 3"]]),
    C6_4 = format_count(ch6_counts[["Set 4"]]),
    C6_5 = format_count(ch6_counts[["Set 5"]]),
    C6_6 = format_count(ch6_counts[["Set 6"]]),
    C6_7 = format_count(ch6_counts[["Set 7"]]),
    C6_8 = format_count(sum(ch6_counts[c("Set 8.1", "Set 8.2")], na.rm = TRUE)),
    C6_9 = format_count(ch6_counts[["Set 9"]]),
    C6_10 = format_count(ch6_counts[["Set 10"]])
  )
)
```
